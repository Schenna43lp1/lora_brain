### ğŸ§  LoRA Brain â€“ Windows Qwen1.5 Trainer

Ein ultraschneller, einfacher LoRA-Trainer fÃ¼r Windows 10/11.
Optimiert fÃ¼r NVIDIA-GPUs, Python 3.11 und lokale Modelle.

Dies ist die sauberste & stabilste Windows-LoRA-Pipeline, ideal fÃ¼r kleine Datensets, Chat-Finetuning oder Custom-Assistants.

### ğŸ“¦ Voraussetzungen
âœ” GPU

### NVIDIA GPU (4â€“12GB VRAM empfohlen)

Neueste NVIDIA-Treiber

âœ” Software

Python 3.11 installiert

PowerShell geÃ¶ffnet

Virtuelle Umgebung erstellt:
Â´Â´Â´
python3.11 -m venv venv
.\venv\Scripts\activate
Â´Â´Â´
âœ” Notwendige Pakete installieren
pip install transformers datasets accelerate peft bitsandbytes sentencepiece

### ğŸ“ Projektstruktur
lora_brain/
â”‚
â”œâ”€â”€ train_win_lora.py      # Haupt-Training-Script
â”œâ”€â”€ training.jsonl         # Dein Trainings-Dataset
â””â”€â”€ models/
      â””â”€â”€ Qwen1.5-1.8B-Chat/   # Lokal entpacktes Modell

### ğŸ“š Dataset-Format (training.jsonl)

Jede Zeile:
```
{"input": "Frage des Nutzers", "output": "Antwort des Modells"}
``` 

Beispiel:

{"input": "Was ist 2+2?", "output": "Die Antwort ist 4."}

### ğŸš€ Training starten
.\venv\Scripts\activate
python train_win_lora.py

### ğŸ›  Was das Script macht

LÃ¤dt dein lokales Modell

Aktiviert LoRA (q_proj, v_proj, k_proj, o_proj)

Tokenisiert dein Dataset stabil fÃ¼r Windows

Startet ein schnelles Training (FP16)

Speichert das fertige LoRA-Modell in:

./output_lora/
